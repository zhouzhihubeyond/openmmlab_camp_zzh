2023-02-06 23:30:10,501 - mmcls - INFO - Environment info:
------------------------------------------------------------
sys.platform: win32
Python: 3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]
CUDA available: True
GPU 0: Quadro T2000
CUDA_HOME: None
MSVC: 用于 x64 的 Microsoft (R) C/C++ 优化编译器 19.27.29111 版
GCC: n/a
PyTorch: 1.12.1
PyTorch compiling details: PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.2.2
OpenCV: 4.6.0
MMCV: 1.6.2
MMCV Compiler: MSVC 192829924
MMCV CUDA Compiler: 11.3
MMClassification: 0.25.0+
------------------------------------------------------------

2023-02-06 23:30:10,502 - mmcls - INFO - Distributed training: False
2023-02-06 23:30:10,610 - mmcls - INFO - Config:
model = dict(
    type='ImageClassifier',
    backbone=dict(type='MobileNetV2', widen_factor=1.0),
    neck=dict(type='GlobalAveragePooling'),
    head=dict(
        type='LinearClsHead',
        num_classes=5,
        in_channels=1280,
        loss=dict(type='CrossEntropyLoss', loss_weight=1.0),
        topk=(1, 5)))
load_from = 'mobilenet_v2_batch256_imagenet_20200708-3b2dc3af.pth'
data = dict(
    samples_per_gpu=32,
    workers_per_gpu=2,
    train=dict(
        type='CustomDataset',
        data_prefix='data/flower_dataset/train',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='RandomResizedCrop', size=224, backend='pillow'),
            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='ToTensor', keys=['gt_label']),
            dict(type='Collect', keys=['img', 'gt_label'])
        ]),
    val=dict(
        type='CustomDataset',
        data_prefix='data/flower_dataset/val',
        ann_file=None,
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', size=(256, -1), backend='pillow'),
            dict(type='CenterCrop', crop_size=224),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ]),
    test=dict(
        type='CustomDataset',
        data_prefix='data/flower_dataset/val',
        ann_file=None,
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', size=(256, -1), backend='pillow'),
            dict(type='CenterCrop', crop_size=224),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ]))
evaluation = dict(interval=1, metric='accuracy')
optimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=4e-05)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', gamma=0.5, step=1)
runner = dict(type='EpochBasedRunner', max_epochs=5)
checkpoint_config = dict(interval=5)
log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
resume_from = None
workflow = [('train', 1)]
work_dir = './work_dirs\mobilenet-v2_flower'
gpu_ids = range(0, 1)

2023-02-06 23:30:10,612 - mmcls - INFO - Set random seed to 1719769723, deterministic: False
2023-02-06 23:30:10,674 - mmcls - INFO - initialize MobileNetV2 with init_cfg [{'type': 'Kaiming', 'layer': ['Conv2d']}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2023-02-06 23:30:10,719 - mmcls - INFO - initialize LinearClsHead with init_cfg {'type': 'Normal', 'layer': 'Linear', 'std': 0.01}
Name of parameter - Initialization information

backbone.conv1.conv.weight - torch.Size([32, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv1.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.conv1.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv.0.conv.weight - torch.Size([32, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.conv.0.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv.0.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv.1.conv.weight - torch.Size([16, 32, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.conv.1.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.0.conv.1.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv.0.conv.weight - torch.Size([96, 16, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.conv.0.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv.0.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv.1.conv.weight - torch.Size([96, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.conv.1.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv.1.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv.2.conv.weight - torch.Size([24, 96, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.conv.2.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.0.conv.2.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv.0.conv.weight - torch.Size([144, 24, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.conv.0.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv.0.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv.1.conv.weight - torch.Size([144, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.conv.1.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv.1.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv.2.conv.weight - torch.Size([24, 144, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.conv.2.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.1.conv.2.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv.0.conv.weight - torch.Size([144, 24, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.conv.0.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv.0.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv.1.conv.weight - torch.Size([144, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.conv.1.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv.1.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv.2.conv.weight - torch.Size([32, 144, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.conv.2.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.0.conv.2.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv.0.conv.weight - torch.Size([192, 32, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.conv.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv.1.conv.weight - torch.Size([192, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.conv.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv.2.conv.weight - torch.Size([32, 192, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.conv.2.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.1.conv.2.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv.0.conv.weight - torch.Size([192, 32, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.conv.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv.1.conv.weight - torch.Size([192, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.conv.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv.2.conv.weight - torch.Size([32, 192, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.conv.2.bn.weight - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.2.conv.2.bn.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv.0.conv.weight - torch.Size([192, 32, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.conv.0.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv.0.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv.1.conv.weight - torch.Size([192, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.conv.1.bn.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv.1.bn.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv.2.conv.weight - torch.Size([64, 192, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.conv.2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.0.conv.2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv.0.conv.weight - torch.Size([384, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.conv.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv.1.conv.weight - torch.Size([384, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.conv.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv.2.conv.weight - torch.Size([64, 384, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.conv.2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.1.conv.2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv.0.conv.weight - torch.Size([384, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.conv.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv.1.conv.weight - torch.Size([384, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.conv.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv.2.conv.weight - torch.Size([64, 384, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.conv.2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.2.conv.2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.3.conv.0.conv.weight - torch.Size([384, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.3.conv.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.3.conv.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.3.conv.1.conv.weight - torch.Size([384, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.3.conv.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.3.conv.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.3.conv.2.conv.weight - torch.Size([64, 384, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.3.conv.2.bn.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.3.conv.2.bn.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.0.conv.0.conv.weight - torch.Size([384, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.0.conv.0.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.0.conv.0.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.0.conv.1.conv.weight - torch.Size([384, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.0.conv.1.bn.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.0.conv.1.bn.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.0.conv.2.conv.weight - torch.Size([96, 384, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.0.conv.2.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.0.conv.2.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.1.conv.0.conv.weight - torch.Size([576, 96, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.1.conv.0.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.1.conv.0.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.1.conv.1.conv.weight - torch.Size([576, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.1.conv.1.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.1.conv.1.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.1.conv.2.conv.weight - torch.Size([96, 576, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.1.conv.2.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.1.conv.2.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.2.conv.0.conv.weight - torch.Size([576, 96, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.2.conv.0.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.2.conv.0.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.2.conv.1.conv.weight - torch.Size([576, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.2.conv.1.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.2.conv.1.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.2.conv.2.conv.weight - torch.Size([96, 576, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer5.2.conv.2.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.2.conv.2.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.0.conv.0.conv.weight - torch.Size([576, 96, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.0.conv.0.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.0.conv.0.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.0.conv.1.conv.weight - torch.Size([576, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.0.conv.1.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.0.conv.1.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.0.conv.2.conv.weight - torch.Size([160, 576, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.0.conv.2.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.0.conv.2.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.1.conv.0.conv.weight - torch.Size([960, 160, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.1.conv.0.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.1.conv.0.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.1.conv.1.conv.weight - torch.Size([960, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.1.conv.1.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.1.conv.1.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.1.conv.2.conv.weight - torch.Size([160, 960, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.1.conv.2.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.1.conv.2.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.2.conv.0.conv.weight - torch.Size([960, 160, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.2.conv.0.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.2.conv.0.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.2.conv.1.conv.weight - torch.Size([960, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.2.conv.1.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.2.conv.1.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.2.conv.2.conv.weight - torch.Size([160, 960, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer6.2.conv.2.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.2.conv.2.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.0.conv.0.conv.weight - torch.Size([960, 160, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer7.0.conv.0.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.0.conv.0.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.0.conv.1.conv.weight - torch.Size([960, 1, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer7.0.conv.1.bn.weight - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.0.conv.1.bn.bias - torch.Size([960]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.0.conv.2.conv.weight - torch.Size([320, 960, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer7.0.conv.2.bn.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.0.conv.2.bn.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.conv2.conv.weight - torch.Size([1280, 320, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv2.bn.weight - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.conv2.bn.bias - torch.Size([1280]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

head.fc.weight - torch.Size([5, 1280]): 
NormalInit: mean=0, std=0.01, bias=0 

head.fc.bias - torch.Size([5]): 
NormalInit: mean=0, std=0.01, bias=0 
2023-02-06 23:30:12,082 - mmcls - INFO - load checkpoint from local path: mobilenet_v2_batch256_imagenet_20200708-3b2dc3af.pth
2023-02-06 23:30:12,133 - mmcls - WARNING - The model and loaded state dict do not match exactly

size mismatch for head.fc.weight: copying a param with shape torch.Size([1000, 1280]) from checkpoint, the shape in current model is torch.Size([5, 1280]).
size mismatch for head.fc.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([5]).
2023-02-06 23:30:12,134 - mmcls - INFO - Start running, host: 86159@zhouzhihu, work_dir: D:\DeepLearning\openmmlab\day3\work_dirs\mobilenet-v2_flower
2023-02-06 23:30:12,135 - mmcls - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-06 23:30:12,135 - mmcls - INFO - workflow: [('train', 1)], max: 5 epochs
2023-02-06 23:30:12,137 - mmcls - INFO - Checkpoints will be saved to D:\DeepLearning\openmmlab\day3\work_dirs\mobilenet-v2_flower by HardDiskBackend.
2023-02-06 23:30:30,750 - mmcls - INFO - Epoch [1][10/72]	lr: 5.000e-03, eta: 0:10:46, time: 1.847, data_time: 1.202, memory: 2455, loss: 1.2185
2023-02-06 23:30:33,268 - mmcls - INFO - Epoch [1][20/72]	lr: 5.000e-03, eta: 0:05:56, time: 0.252, data_time: 0.015, memory: 2455, loss: 0.4202
2023-02-06 23:30:35,770 - mmcls - INFO - Epoch [1][30/72]	lr: 5.000e-03, eta: 0:04:18, time: 0.250, data_time: 0.015, memory: 2455, loss: 0.3863
2023-02-06 23:30:38,284 - mmcls - INFO - Epoch [1][40/72]	lr: 5.000e-03, eta: 0:03:28, time: 0.251, data_time: 0.015, memory: 2455, loss: 0.4777
2023-02-06 23:30:40,790 - mmcls - INFO - Epoch [1][50/72]	lr: 5.000e-03, eta: 0:02:56, time: 0.251, data_time: 0.015, memory: 2455, loss: 0.4302
2023-02-06 23:30:43,300 - mmcls - INFO - Epoch [1][60/72]	lr: 5.000e-03, eta: 0:02:35, time: 0.251, data_time: 0.015, memory: 2455, loss: 0.4634
2023-02-06 23:30:45,812 - mmcls - INFO - Epoch [1][70/72]	lr: 5.000e-03, eta: 0:02:18, time: 0.251, data_time: 0.015, memory: 2455, loss: 0.4905
2023-02-06 23:30:58,009 - mmcls - INFO - Epoch(val) [1][18]	accuracy_top-1: 86.8881, accuracy_top-5: 100.0000
2023-02-06 23:31:02,864 - mmcls - INFO - Epoch [2][10/72]	lr: 2.500e-03, eta: 0:02:09, time: 0.471, data_time: 0.220, memory: 2455, loss: 0.3357
2023-02-06 23:31:05,369 - mmcls - INFO - Epoch [2][20/72]	lr: 2.500e-03, eta: 0:01:58, time: 0.251, data_time: 0.015, memory: 2455, loss: 0.2933
2023-02-06 23:31:07,878 - mmcls - INFO - Epoch [2][30/72]	lr: 2.500e-03, eta: 0:01:49, time: 0.251, data_time: 0.015, memory: 2455, loss: 0.2956
2023-02-06 23:31:10,384 - mmcls - INFO - Epoch [2][40/72]	lr: 2.500e-03, eta: 0:01:41, time: 0.251, data_time: 0.014, memory: 2455, loss: 0.2411
2023-02-06 23:31:12,897 - mmcls - INFO - Epoch [2][50/72]	lr: 2.500e-03, eta: 0:01:34, time: 0.251, data_time: 0.014, memory: 2455, loss: 0.2806
2023-02-06 23:31:15,410 - mmcls - INFO - Epoch [2][60/72]	lr: 2.500e-03, eta: 0:01:27, time: 0.251, data_time: 0.015, memory: 2455, loss: 0.2760
2023-02-06 23:31:17,926 - mmcls - INFO - Epoch [2][70/72]	lr: 2.500e-03, eta: 0:01:21, time: 0.252, data_time: 0.015, memory: 2455, loss: 0.2644
2023-02-06 23:31:20,207 - mmcls - INFO - Epoch(val) [2][18]	accuracy_top-1: 94.7552, accuracy_top-5: 100.0000
2023-02-06 23:31:25,043 - mmcls - INFO - Epoch [3][10/72]	lr: 1.250e-03, eta: 0:01:17, time: 0.469, data_time: 0.218, memory: 2455, loss: 0.2848
2023-02-06 23:31:27,556 - mmcls - INFO - Epoch [3][20/72]	lr: 1.250e-03, eta: 0:01:12, time: 0.251, data_time: 0.014, memory: 2455, loss: 0.2359
2023-02-06 23:31:30,076 - mmcls - INFO - Epoch [3][30/72]	lr: 1.250e-03, eta: 0:01:07, time: 0.252, data_time: 0.014, memory: 2455, loss: 0.2136
2023-02-06 23:31:32,599 - mmcls - INFO - Epoch [3][40/72]	lr: 1.250e-03, eta: 0:01:02, time: 0.252, data_time: 0.014, memory: 2455, loss: 0.2506
2023-02-06 23:31:35,119 - mmcls - INFO - Epoch [3][50/72]	lr: 1.250e-03, eta: 0:00:58, time: 0.252, data_time: 0.014, memory: 2455, loss: 0.1816
2023-02-06 23:31:37,635 - mmcls - INFO - Epoch [3][60/72]	lr: 1.250e-03, eta: 0:00:53, time: 0.251, data_time: 0.014, memory: 2455, loss: 0.2214
2023-02-06 23:31:40,162 - mmcls - INFO - Epoch [3][70/72]	lr: 1.250e-03, eta: 0:00:49, time: 0.252, data_time: 0.014, memory: 2455, loss: 0.2269
2023-02-06 23:31:42,217 - mmcls - INFO - Epoch(val) [3][18]	accuracy_top-1: 93.8811, accuracy_top-5: 100.0000
2023-02-06 23:31:47,034 - mmcls - INFO - Epoch [4][10/72]	lr: 6.250e-04, eta: 0:00:46, time: 0.467, data_time: 0.216, memory: 2455, loss: 0.1632
2023-02-06 23:31:49,545 - mmcls - INFO - Epoch [4][20/72]	lr: 6.250e-04, eta: 0:00:42, time: 0.251, data_time: 0.015, memory: 2455, loss: 0.2125
2023-02-06 23:31:52,057 - mmcls - INFO - Epoch [4][30/72]	lr: 6.250e-04, eta: 0:00:38, time: 0.251, data_time: 0.015, memory: 2455, loss: 0.1541
2023-02-06 23:31:54,572 - mmcls - INFO - Epoch [4][40/72]	lr: 6.250e-04, eta: 0:00:34, time: 0.251, data_time: 0.014, memory: 2455, loss: 0.2445
2023-02-06 23:31:57,085 - mmcls - INFO - Epoch [4][50/72]	lr: 6.250e-04, eta: 0:00:31, time: 0.252, data_time: 0.014, memory: 2455, loss: 0.2652
2023-02-06 23:31:59,598 - mmcls - INFO - Epoch [4][60/72]	lr: 6.250e-04, eta: 0:00:27, time: 0.251, data_time: 0.014, memory: 2455, loss: 0.1588
2023-02-06 23:32:02,110 - mmcls - INFO - Epoch [4][70/72]	lr: 6.250e-04, eta: 0:00:24, time: 0.251, data_time: 0.015, memory: 2455, loss: 0.1736
2023-02-06 23:32:04,253 - mmcls - INFO - Epoch(val) [4][18]	accuracy_top-1: 94.9301, accuracy_top-5: 100.0000
2023-02-06 23:32:09,015 - mmcls - INFO - Epoch [5][10/72]	lr: 3.125e-04, eta: 0:00:20, time: 0.462, data_time: 0.215, memory: 2455, loss: 0.1614
2023-02-06 23:32:11,531 - mmcls - INFO - Epoch [5][20/72]	lr: 3.125e-04, eta: 0:00:16, time: 0.252, data_time: 0.015, memory: 2455, loss: 0.1765
2023-02-06 23:32:14,044 - mmcls - INFO - Epoch [5][30/72]	lr: 3.125e-04, eta: 0:00:13, time: 0.251, data_time: 0.014, memory: 2455, loss: 0.1617
2023-02-06 23:32:16,557 - mmcls - INFO - Epoch [5][40/72]	lr: 3.125e-04, eta: 0:00:10, time: 0.251, data_time: 0.014, memory: 2455, loss: 0.1219
2023-02-06 23:32:19,070 - mmcls - INFO - Epoch [5][50/72]	lr: 3.125e-04, eta: 0:00:06, time: 0.251, data_time: 0.014, memory: 2455, loss: 0.1630
2023-02-06 23:32:21,589 - mmcls - INFO - Epoch [5][60/72]	lr: 3.125e-04, eta: 0:00:03, time: 0.253, data_time: 0.014, memory: 2455, loss: 0.1775
2023-02-06 23:32:24,100 - mmcls - INFO - Epoch [5][70/72]	lr: 3.125e-04, eta: 0:00:00, time: 0.250, data_time: 0.014, memory: 2455, loss: 0.1399
2023-02-06 23:32:24,385 - mmcls - INFO - Saving checkpoint at 5 epochs
2023-02-06 23:32:26,319 - mmcls - INFO - Epoch(val) [5][18]	accuracy_top-1: 95.4545, accuracy_top-5: 100.0000
