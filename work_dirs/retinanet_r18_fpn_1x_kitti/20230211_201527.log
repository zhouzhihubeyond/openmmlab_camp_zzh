2023-02-11 20:15:35,032 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: win32
Python: 3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]
CUDA available: True
GPU 0: Quadro T2000
CUDA_HOME: None
MSVC: 用于 x64 的 Microsoft (R) C/C++ 优化编译器 19.27.29111 版
GCC: n/a
PyTorch: 1.12.1
PyTorch compiling details: PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.3.2  (built against CUDA 11.5)
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.2.2
OpenCV: 4.6.0
MMCV: 1.6.2
MMCV Compiler: MSVC 192829924
MMCV CUDA Compiler: 11.3
MMDetection: 2.28.1+
------------------------------------------------------------

2023-02-11 20:15:35,220 - mmdet - INFO - Distributed training: False
2023-02-11 20:15:35,450 - mmdet - INFO - Config:
model = dict(
    type='RetinaNet',
    backbone=dict(
        type='ResNet',
        depth=18,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=True,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[64, 128, 256, 512],
        out_channels=256,
        start_level=1,
        add_extra_convs='on_input',
        num_outs=5),
    bbox_head=dict(
        type='RetinaHead',
        num_classes=8,
        in_channels=256,
        stacked_convs=4,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            octave_base_scale=4,
            scales_per_octave=3,
            ratios=[0.5, 1.0, 2.0],
            strides=[8, 16, 32, 64, 128]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
    train_cfg=dict(
        assigner=dict(
            type='MaxIoUAssigner',
            pos_iou_thr=0.5,
            neg_iou_thr=0.4,
            min_pos_iou=0,
            ignore_iof_thr=-1),
        allowed_border=-1,
        pos_weight=-1,
        debug=False),
    test_cfg=dict(
        nms_pre=1000,
        min_bbox_size=0,
        score_thr=0.05,
        nms=dict(type='nms', iou_threshold=0.5),
        max_per_img=100))
load_from = 'retinanet_r18_fpn_1x_coco_20220407_171055-614fd399.pth'
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='CustomDataset',
        ann_file='data/kitti_tiny/train_ann.pkl',
        img_prefix='data/kitti_tiny/training/image_2',
        classes=[
            'Pedestrian', 'Truck', 'Car', 'Cyclist', 'Misc', 'Van', 'Tram',
            'Person_sitting'
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ]),
    val=dict(
        type='CustomDataset',
        ann_file='data/kitti_tiny/test_ann.pkl',
        img_prefix='data/kitti_tiny/training/image_2',
        classes=[
            'Pedestrian', 'Truck', 'Car', 'Cyclist', 'Misc', 'Van', 'Tram',
            'Person_sitting'
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CustomDataset',
        ann_file='data/kitti_tiny/test_ann.pkl',
        img_prefix='data/kitti_tiny/training/image_2',
        classes=[
            'Pedestrian', 'Truck', 'Car', 'Cyclist', 'Misc', 'Van', 'Tram',
            'Person_sitting'
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=4, metric='mAP')
optimizer = dict(type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=50,
    warmup_ratio=0.001,
    step=[8, 11])
runner = dict(type='EpochBasedRunner', max_epochs=12)
checkpoint_config = dict(interval=12)
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
auto_scale_lr = dict(enable=False, base_batch_size=16)
work_dir = './work_dirs\retinanet_r18_fpn_1x_kitti'
auto_resume = False
gpu_ids = range(0, 1)

2023-02-11 20:15:35,453 - mmdet - INFO - Set random seed to 290739068, deterministic: False
2023-02-11 20:15:35,653 - mmdet - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2023-02-11 20:15:35,738 - mmdet - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}
2023-02-11 20:15:35,739 - mmdet - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}
2023-02-11 20:15:35,740 - mmdet - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}
2023-02-11 20:15:35,741 - mmdet - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}
2023-02-11 20:15:35,743 - mmdet - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}
2023-02-11 20:15:35,744 - mmdet - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}
2023-02-11 20:15:35,747 - mmdet - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}
2023-02-11 20:15:35,750 - mmdet - INFO - initialize BasicBlock with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm2'}}
2023-02-11 20:15:35,761 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2023-02-11 20:15:35,787 - mmdet - INFO - initialize RetinaHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'retina_cls', 'std': 0.01, 'bias_prob': 0.01}}
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
ConstantInit: val=0, bias=0 

backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer1.1.conv1.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
ConstantInit: val=0, bias=0 

backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer2.0.conv1.weight - torch.Size([128, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
ConstantInit: val=0, bias=0 

backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer2.0.downsample.0.weight - torch.Size([128, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.downsample.1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer2.0.downsample.1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer2.1.conv1.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
ConstantInit: val=0, bias=0 

backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer3.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer3.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer3.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

backbone.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer4.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RetinaNet  

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

backbone.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.lateral_convs.0.conv.weight - torch.Size([256, 128, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.lateral_convs.1.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.lateral_convs.2.conv.weight - torch.Size([256, 512, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.3.conv.weight - torch.Size([256, 512, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.4.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.4.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.retina_cls.weight - torch.Size([72, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

bbox_head.retina_cls.bias - torch.Size([72]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

bbox_head.retina_reg.weight - torch.Size([36, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.retina_reg.bias - torch.Size([36]): 
NormalInit: mean=0, std=0.01, bias=0 
2023-02-11 20:15:37,021 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.
2023-02-11 20:15:37,028 - mmdet - INFO - load checkpoint from local path: retinanet_r18_fpn_1x_coco_20220407_171055-614fd399.pth
2023-02-11 20:15:37,118 - mmdet - WARNING - The model and loaded state dict do not match exactly

size mismatch for bbox_head.retina_cls.weight: copying a param with shape torch.Size([720, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([72, 256, 3, 3]).
size mismatch for bbox_head.retina_cls.bias: copying a param with shape torch.Size([720]) from checkpoint, the shape in current model is torch.Size([72]).
2023-02-11 20:15:37,124 - mmdet - INFO - Start running, host: 86159@zhouzhihu, work_dir: D:\DeepLearning\openmmlab\day5\work_dirs\retinanet_r18_fpn_1x_kitti
2023-02-11 20:15:37,125 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-11 20:15:37,125 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs
2023-02-11 20:15:37,126 - mmdet - INFO - Checkpoints will be saved to D:\DeepLearning\openmmlab\day5\work_dirs\retinanet_r18_fpn_1x_kitti by HardDiskBackend.
2023-02-11 20:16:03,202 - mmdet - INFO - Epoch [1][5/25]	lr: 8.092e-05, eta: 0:25:25, time: 5.171, data_time: 2.566, memory: 711, loss_cls: 1.1994, loss_bbox: 0.2577, loss: 1.4571
2023-02-11 20:16:05,365 - mmdet - INFO - Epoch [1][10/25]	lr: 1.808e-04, eta: 0:13:32, time: 0.432, data_time: 0.046, memory: 711, loss_cls: 1.1751, loss_bbox: 0.2531, loss: 1.4283
2023-02-11 20:16:07,522 - mmdet - INFO - Epoch [1][15/25]	lr: 2.807e-04, eta: 0:09:33, time: 0.431, data_time: 0.047, memory: 711, loss_cls: 1.1508, loss_bbox: 0.1928, loss: 1.3436
2023-02-11 20:16:09,680 - mmdet - INFO - Epoch [1][20/25]	lr: 3.806e-04, eta: 0:07:32, time: 0.431, data_time: 0.047, memory: 711, loss_cls: 1.0880, loss_bbox: 0.2294, loss: 1.3174
2023-02-11 20:16:11,848 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:16:11,855 - mmdet - INFO - Epoch [1][25/25]	lr: 4.805e-04, eta: 0:06:19, time: 0.433, data_time: 0.046, memory: 722, loss_cls: 0.9118, loss_bbox: 0.2728, loss: 1.1847
2023-02-11 20:16:28,848 - mmdet - INFO - Epoch [2][5/25]	lr: 5.804e-04, eta: 0:07:38, time: 3.281, data_time: 2.835, memory: 722, loss_cls: 0.7225, loss_bbox: 0.2379, loss: 0.9604
2023-02-11 20:16:31,022 - mmdet - INFO - Epoch [2][10/25]	lr: 6.803e-04, eta: 0:06:41, time: 0.434, data_time: 0.046, memory: 722, loss_cls: 0.7424, loss_bbox: 0.2413, loss: 0.9837
2023-02-11 20:16:33,181 - mmdet - INFO - Epoch [2][15/25]	lr: 7.802e-04, eta: 0:05:59, time: 0.431, data_time: 0.046, memory: 722, loss_cls: 0.4304, loss_bbox: 0.2023, loss: 0.6328
2023-02-11 20:16:35,360 - mmdet - INFO - Epoch [2][20/25]	lr: 8.801e-04, eta: 0:05:25, time: 0.436, data_time: 0.047, memory: 722, loss_cls: 0.3517, loss_bbox: 0.1988, loss: 0.5505
2023-02-11 20:16:37,525 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:16:37,525 - mmdet - INFO - Epoch [2][25/25]	lr: 9.800e-04, eta: 0:04:57, time: 0.433, data_time: 0.047, memory: 722, loss_cls: 0.4196, loss_bbox: 0.2113, loss: 0.6309
2023-02-11 20:16:54,832 - mmdet - INFO - Epoch [3][5/25]	lr: 1.000e-03, eta: 0:05:39, time: 3.342, data_time: 2.914, memory: 722, loss_cls: 0.2438, loss_bbox: 0.2260, loss: 0.4698
2023-02-11 20:16:56,980 - mmdet - INFO - Epoch [3][10/25]	lr: 1.000e-03, eta: 0:05:13, time: 0.430, data_time: 0.046, memory: 722, loss_cls: 0.3406, loss_bbox: 0.2090, loss: 0.5496
2023-02-11 20:16:59,135 - mmdet - INFO - Epoch [3][15/25]	lr: 1.000e-03, eta: 0:04:51, time: 0.431, data_time: 0.046, memory: 722, loss_cls: 0.4958, loss_bbox: 0.1968, loss: 0.6926
2023-02-11 20:17:01,303 - mmdet - INFO - Epoch [3][20/25]	lr: 1.000e-03, eta: 0:04:31, time: 0.434, data_time: 0.047, memory: 722, loss_cls: 0.3748, loss_bbox: 0.1955, loss: 0.5703
2023-02-11 20:17:03,464 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:17:03,464 - mmdet - INFO - Epoch [3][25/25]	lr: 1.000e-03, eta: 0:04:14, time: 0.432, data_time: 0.046, memory: 722, loss_cls: 0.3916, loss_bbox: 0.2046, loss: 0.5962
2023-02-11 20:17:19,586 - mmdet - INFO - Epoch [4][5/25]	lr: 1.000e-03, eta: 0:04:36, time: 3.096, data_time: 2.651, memory: 722, loss_cls: 0.3218, loss_bbox: 0.1759, loss: 0.4977
2023-02-11 20:17:21,729 - mmdet - INFO - Epoch [4][10/25]	lr: 1.000e-03, eta: 0:04:19, time: 0.428, data_time: 0.046, memory: 722, loss_cls: 0.2792, loss_bbox: 0.1446, loss: 0.4237
2023-02-11 20:17:23,879 - mmdet - INFO - Epoch [4][15/25]	lr: 1.000e-03, eta: 0:04:04, time: 0.430, data_time: 0.046, memory: 722, loss_cls: 0.2557, loss_bbox: 0.2162, loss: 0.4719
2023-02-11 20:17:26,044 - mmdet - INFO - Epoch [4][20/25]	lr: 1.000e-03, eta: 0:03:50, time: 0.433, data_time: 0.047, memory: 722, loss_cls: 0.2721, loss_bbox: 0.1672, loss: 0.4393
2023-02-11 20:17:28,206 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:17:28,207 - mmdet - INFO - Epoch [4][25/25]	lr: 1.000e-03, eta: 0:03:38, time: 0.433, data_time: 0.046, memory: 722, loss_cls: 0.3378, loss_bbox: 0.2167, loss: 0.5545
2023-02-11 20:17:49,059 - mmdet - INFO - 
+----------------+-----+------+--------+-------+
| class          | gts | dets | recall | ap    |
+----------------+-----+------+--------+-------+
| Pedestrian     | 13  | 470  | 0.923  | 0.838 |
| Truck          | 3   | 357  | 1.000  | 0.520 |
| Car            | 62  | 983  | 0.984  | 0.804 |
| Cyclist        | 7   | 64   | 0.143  | 0.003 |
| Misc           | 1   | 37   | 0.000  | 0.000 |
| Van            | 11  | 349  | 0.909  | 0.207 |
| Tram           | 5   | 136  | 0.000  | 0.000 |
| Person_sitting | 5   | 0    | 0.000  | 0.000 |
+----------------+-----+------+--------+-------+
| mAP            |     |      |        | 0.297 |
+----------------+-----+------+--------+-------+
2023-02-11 20:17:49,113 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:17:49,114 - mmdet - INFO - Epoch(val) [4][25]	AP50: 0.2970, mAP: 0.2966
2023-02-11 20:18:05,248 - mmdet - INFO - Epoch [5][5/25]	lr: 1.000e-03, eta: 0:03:52, time: 3.182, data_time: 2.752, memory: 722, loss_cls: 0.2962, loss_bbox: 0.1410, loss: 0.4373
2023-02-11 20:18:07,412 - mmdet - INFO - Epoch [5][10/25]	lr: 1.000e-03, eta: 0:03:39, time: 0.433, data_time: 0.046, memory: 722, loss_cls: 0.2591, loss_bbox: 0.1814, loss: 0.4405
2023-02-11 20:18:09,562 - mmdet - INFO - Epoch [5][15/25]	lr: 1.000e-03, eta: 0:03:27, time: 0.430, data_time: 0.047, memory: 722, loss_cls: 0.1751, loss_bbox: 0.1614, loss: 0.3366
2023-02-11 20:18:11,716 - mmdet - INFO - Epoch [5][20/25]	lr: 1.000e-03, eta: 0:03:17, time: 0.431, data_time: 0.047, memory: 722, loss_cls: 0.2867, loss_bbox: 0.1777, loss: 0.4644
2023-02-11 20:18:13,868 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:18:13,868 - mmdet - INFO - Epoch [5][25/25]	lr: 1.000e-03, eta: 0:03:06, time: 0.430, data_time: 0.046, memory: 722, loss_cls: 0.1704, loss_bbox: 0.2038, loss: 0.3742
2023-02-11 20:18:31,245 - mmdet - INFO - Epoch [6][5/25]	lr: 1.000e-03, eta: 0:03:16, time: 3.365, data_time: 2.920, memory: 722, loss_cls: 0.1987, loss_bbox: 0.1801, loss: 0.3788
2023-02-11 20:18:33,392 - mmdet - INFO - Epoch [6][10/25]	lr: 1.000e-03, eta: 0:03:06, time: 0.429, data_time: 0.046, memory: 722, loss_cls: 0.2016, loss_bbox: 0.1491, loss: 0.3507
2023-02-11 20:18:35,544 - mmdet - INFO - Epoch [6][15/25]	lr: 1.000e-03, eta: 0:02:56, time: 0.430, data_time: 0.046, memory: 722, loss_cls: 0.1880, loss_bbox: 0.1775, loss: 0.3654
2023-02-11 20:18:37,696 - mmdet - INFO - Epoch [6][20/25]	lr: 1.000e-03, eta: 0:02:47, time: 0.431, data_time: 0.046, memory: 722, loss_cls: 0.1847, loss_bbox: 0.1829, loss: 0.3676
2023-02-11 20:18:39,840 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:18:39,840 - mmdet - INFO - Epoch [6][25/25]	lr: 1.000e-03, eta: 0:02:38, time: 0.428, data_time: 0.046, memory: 722, loss_cls: 0.2453, loss_bbox: 0.1300, loss: 0.3752
2023-02-11 20:18:56,417 - mmdet - INFO - Epoch [7][5/25]	lr: 1.000e-03, eta: 0:02:43, time: 3.209, data_time: 2.758, memory: 722, loss_cls: 0.2280, loss_bbox: 0.1760, loss: 0.4041
2023-02-11 20:18:58,576 - mmdet - INFO - Epoch [7][10/25]	lr: 1.000e-03, eta: 0:02:35, time: 0.432, data_time: 0.047, memory: 722, loss_cls: 0.2047, loss_bbox: 0.1550, loss: 0.3597
2023-02-11 20:19:00,722 - mmdet - INFO - Epoch [7][15/25]	lr: 1.000e-03, eta: 0:02:26, time: 0.429, data_time: 0.046, memory: 722, loss_cls: 0.1800, loss_bbox: 0.1470, loss: 0.3270
2023-02-11 20:19:02,878 - mmdet - INFO - Epoch [7][20/25]	lr: 1.000e-03, eta: 0:02:18, time: 0.431, data_time: 0.046, memory: 722, loss_cls: 0.1806, loss_bbox: 0.1485, loss: 0.3291
2023-02-11 20:19:05,038 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:19:05,038 - mmdet - INFO - Epoch [7][25/25]	lr: 1.000e-03, eta: 0:02:11, time: 0.432, data_time: 0.046, memory: 722, loss_cls: 0.1703, loss_bbox: 0.1672, loss: 0.3375
2023-02-11 20:19:22,186 - mmdet - INFO - Epoch [8][5/25]	lr: 1.000e-03, eta: 0:02:13, time: 3.323, data_time: 2.872, memory: 722, loss_cls: 0.1455, loss_bbox: 0.1523, loss: 0.2977
2023-02-11 20:19:24,343 - mmdet - INFO - Epoch [8][10/25]	lr: 1.000e-03, eta: 0:02:05, time: 0.431, data_time: 0.046, memory: 722, loss_cls: 0.1259, loss_bbox: 0.1403, loss: 0.2662
2023-02-11 20:19:26,492 - mmdet - INFO - Epoch [8][15/25]	lr: 1.000e-03, eta: 0:01:58, time: 0.429, data_time: 0.046, memory: 722, loss_cls: 0.1830, loss_bbox: 0.1452, loss: 0.3281
2023-02-11 20:19:28,651 - mmdet - INFO - Epoch [8][20/25]	lr: 1.000e-03, eta: 0:01:51, time: 0.432, data_time: 0.047, memory: 722, loss_cls: 0.1474, loss_bbox: 0.1682, loss: 0.3157
2023-02-11 20:19:30,802 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:19:30,802 - mmdet - INFO - Epoch [8][25/25]	lr: 1.000e-03, eta: 0:01:44, time: 0.430, data_time: 0.046, memory: 722, loss_cls: 0.1853, loss_bbox: 0.1328, loss: 0.3180
2023-02-11 20:19:50,804 - mmdet - INFO - 
+----------------+-----+------+--------+-------+
| class          | gts | dets | recall | ap    |
+----------------+-----+------+--------+-------+
| Pedestrian     | 13  | 484  | 0.923  | 0.796 |
| Truck          | 3   | 299  | 1.000  | 0.681 |
| Car            | 62  | 618  | 0.984  | 0.775 |
| Cyclist        | 7   | 179  | 0.286  | 0.010 |
| Misc           | 1   | 145  | 0.000  | 0.000 |
| Van            | 11  | 277  | 0.909  | 0.296 |
| Tram           | 5   | 181  | 0.400  | 0.010 |
| Person_sitting | 5   | 0    | 0.000  | 0.000 |
+----------------+-----+------+--------+-------+
| mAP            |     |      |        | 0.321 |
+----------------+-----+------+--------+-------+
2023-02-11 20:19:50,860 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:19:50,860 - mmdet - INFO - Epoch(val) [8][25]	AP50: 0.3210, mAP: 0.3208
2023-02-11 20:20:06,658 - mmdet - INFO - Epoch [9][5/25]	lr: 1.000e-04, eta: 0:01:44, time: 3.115, data_time: 2.683, memory: 722, loss_cls: 0.1436, loss_bbox: 0.1903, loss: 0.3340
2023-02-11 20:20:08,812 - mmdet - INFO - Epoch [9][10/25]	lr: 1.000e-04, eta: 0:01:37, time: 0.431, data_time: 0.046, memory: 722, loss_cls: 0.1446, loss_bbox: 0.1477, loss: 0.2923
2023-02-11 20:20:10,963 - mmdet - INFO - Epoch [9][15/25]	lr: 1.000e-04, eta: 0:01:30, time: 0.430, data_time: 0.046, memory: 722, loss_cls: 0.1332, loss_bbox: 0.1371, loss: 0.2703
2023-02-11 20:20:13,109 - mmdet - INFO - Epoch [9][20/25]	lr: 1.000e-04, eta: 0:01:23, time: 0.429, data_time: 0.046, memory: 722, loss_cls: 0.1225, loss_bbox: 0.1074, loss: 0.2299
2023-02-11 20:20:15,265 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:20:15,265 - mmdet - INFO - Epoch [9][25/25]	lr: 1.000e-04, eta: 0:01:17, time: 0.431, data_time: 0.046, memory: 722, loss_cls: 0.1286, loss_bbox: 0.1303, loss: 0.2589
2023-02-11 20:20:32,019 - mmdet - INFO - Epoch [10][5/25]	lr: 1.000e-04, eta: 0:01:15, time: 3.246, data_time: 2.781, memory: 722, loss_cls: 0.1268, loss_bbox: 0.1438, loss: 0.2706
2023-02-11 20:20:34,182 - mmdet - INFO - Epoch [10][10/25]	lr: 1.000e-04, eta: 0:01:09, time: 0.429, data_time: 0.042, memory: 722, loss_cls: 0.0996, loss_bbox: 0.1288, loss: 0.2284
2023-02-11 20:20:36,334 - mmdet - INFO - Epoch [10][15/25]	lr: 1.000e-04, eta: 0:01:03, time: 0.430, data_time: 0.045, memory: 722, loss_cls: 0.1274, loss_bbox: 0.0939, loss: 0.2214
2023-02-11 20:20:38,493 - mmdet - INFO - Epoch [10][20/25]	lr: 1.000e-04, eta: 0:00:57, time: 0.432, data_time: 0.046, memory: 722, loss_cls: 0.1513, loss_bbox: 0.1239, loss: 0.2752
2023-02-11 20:20:40,660 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:20:40,660 - mmdet - INFO - Epoch [10][25/25]	lr: 1.000e-04, eta: 0:00:51, time: 0.433, data_time: 0.046, memory: 722, loss_cls: 0.1577, loss_bbox: 0.1536, loss: 0.3113
2023-02-11 20:20:57,175 - mmdet - INFO - Epoch [11][5/25]	lr: 1.000e-04, eta: 0:00:48, time: 3.195, data_time: 2.743, memory: 722, loss_cls: 0.1330, loss_bbox: 0.1421, loss: 0.2751
2023-02-11 20:20:59,312 - mmdet - INFO - Epoch [11][10/25]	lr: 1.000e-04, eta: 0:00:42, time: 0.428, data_time: 0.046, memory: 722, loss_cls: 0.1081, loss_bbox: 0.0929, loss: 0.2010
2023-02-11 20:21:01,468 - mmdet - INFO - Epoch [11][15/25]	lr: 1.000e-04, eta: 0:00:36, time: 0.431, data_time: 0.046, memory: 722, loss_cls: 0.1682, loss_bbox: 0.1571, loss: 0.3254
2023-02-11 20:21:03,622 - mmdet - INFO - Epoch [11][20/25]	lr: 1.000e-04, eta: 0:00:31, time: 0.431, data_time: 0.046, memory: 722, loss_cls: 0.1478, loss_bbox: 0.1592, loss: 0.3070
2023-02-11 20:21:05,777 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:21:05,777 - mmdet - INFO - Epoch [11][25/25]	lr: 1.000e-04, eta: 0:00:25, time: 0.431, data_time: 0.046, memory: 722, loss_cls: 0.0936, loss_bbox: 0.1164, loss: 0.2100
2023-02-11 20:21:21,764 - mmdet - INFO - Epoch [12][5/25]	lr: 1.000e-05, eta: 0:00:21, time: 3.094, data_time: 2.647, memory: 722, loss_cls: 0.1159, loss_bbox: 0.1095, loss: 0.2255
2023-02-11 20:21:23,904 - mmdet - INFO - Epoch [12][10/25]	lr: 1.000e-05, eta: 0:00:15, time: 0.428, data_time: 0.046, memory: 722, loss_cls: 0.1648, loss_bbox: 0.1265, loss: 0.2914
2023-02-11 20:21:26,047 - mmdet - INFO - Epoch [12][15/25]	lr: 1.000e-05, eta: 0:00:10, time: 0.429, data_time: 0.046, memory: 722, loss_cls: 0.1337, loss_bbox: 0.1280, loss: 0.2618
2023-02-11 20:21:28,199 - mmdet - INFO - Epoch [12][20/25]	lr: 1.000e-05, eta: 0:00:05, time: 0.430, data_time: 0.046, memory: 722, loss_cls: 0.1027, loss_bbox: 0.1531, loss: 0.2558
2023-02-11 20:21:30,350 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:21:30,350 - mmdet - INFO - Epoch [12][25/25]	lr: 1.000e-05, eta: 0:00:00, time: 0.430, data_time: 0.046, memory: 722, loss_cls: 0.1538, loss_bbox: 0.1748, loss: 0.3286
2023-02-11 20:21:30,643 - mmdet - INFO - Saving checkpoint at 12 epochs
2023-02-11 20:21:51,611 - mmdet - INFO - 
+----------------+-----+------+--------+-------+
| class          | gts | dets | recall | ap    |
+----------------+-----+------+--------+-------+
| Pedestrian     | 13  | 491  | 0.923  | 0.788 |
| Truck          | 3   | 204  | 1.000  | 0.810 |
| Car            | 62  | 687  | 0.984  | 0.780 |
| Cyclist        | 7   | 199  | 0.286  | 0.010 |
| Misc           | 1   | 135  | 0.000  | 0.000 |
| Van            | 11  | 278  | 0.909  | 0.268 |
| Tram           | 5   | 148  | 0.400  | 0.012 |
| Person_sitting | 5   | 0    | 0.000  | 0.000 |
+----------------+-----+------+--------+-------+
| mAP            |     |      |        | 0.333 |
+----------------+-----+------+--------+-------+
2023-02-11 20:21:51,663 - mmdet - INFO - Exp name: retinanet_r18_fpn_1x_kitti.py
2023-02-11 20:21:51,664 - mmdet - INFO - Epoch(val) [12][25]	AP50: 0.3330, mAP: 0.3334
